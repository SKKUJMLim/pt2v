{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c8dab41-4ce2-47f9-8a37-9627031ddb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88ac6ddb-707f-49b0-a866-877c925bbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import sys, os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# (선택) decord로 비디오 읽기 – 안 쓰고 직접 frame 텐서를 만들고 싶으면 이 부분만 바꿔도 됨\n",
    "from decord import VideoReader, cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "628c163d-e526-461a-9af8-e22e342fe24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0199d027-bc4a-4f69-964b-a1f83bab2800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\JM/.cache\\torch\\hub\\facebookresearch_vjepa2_main\n",
      "Using cache found in C:\\Users\\JM/.cache\\torch\\hub\\facebookresearch_vjepa2_main\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 1. device 설정 & 모델 / preprocessor 로드\n",
    "# -----------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# torch.hub에서 preprocessor / encoder 로드\n",
    "processor = torch.hub.load('facebookresearch/vjepa2', 'vjepa2_preprocessor')\n",
    "loaded  = torch.hub.load('facebookresearch/vjepa2', 'vjepa2_vit_giant')\n",
    "\n",
    "if isinstance(loaded, tuple):\n",
    "    vjepa2_encoder = loaded[0]    # encoder만 사용\n",
    "else:\n",
    "    vjepa2_encoder = loaded\n",
    "\n",
    "vjepa2_encoder = vjepa2_encoder.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9083ec69-9d29-4cd7-adb1-40ad671c979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: ['../A tiger leaping over a small rock on a flat ground\\\\_0.jpg', '../A tiger leaping over a small rock on a flat ground\\\\_1.jpg', '../A tiger leaping over a small rock on a flat ground\\\\_2.jpg', '../A tiger leaping over a small rock on a flat ground\\\\_3.jpg', '../A tiger leaping over a small rock on a flat ground\\\\_4.jpg', '../A tiger leaping over a small rock on a flat ground\\\\_5.jpg', '../A tiger leaping over a small rock on a flat ground\\\\_6.jpg', '../A tiger leaping over a small rock on a flat ground\\\\_7.jpg']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 2. frames 폴더에서 _0.jpg ~ _7.jpg 읽기\n",
    "# ---------------------------------------------------\n",
    "# frames_dir = \"../A horse galloping on a street\"\n",
    "# frames_dir = \"A basketball free falls in the air\"\n",
    "frames_dir = \"../A tiger leaping over a small rock on a flat ground\"\n",
    "\n",
    "# 파일 목록 정렬 (_0.jpg, _1.jpg, ... 순서 보장)\n",
    "frame_paths = glob.glob(os.path.join(frames_dir, \"*.jpg\"))\n",
    "\n",
    "def frame_key(path):\n",
    "    # 예: path = \"frames/_3.jpg\" -> stem = \"_3\" -> idx = 3\n",
    "    name = os.path.splitext(os.path.basename(path))[0]  # \"_3\"\n",
    "    idx = int(name.split(\"_\")[-1])\n",
    "    return idx\n",
    "\n",
    "frame_paths = sorted(frame_paths, key=frame_key)\n",
    "\n",
    "print(\"frames:\", frame_paths)\n",
    "\n",
    "# 각 프레임을 np.ndarray(H,W,3)로 읽어서 리스트로 만들기\n",
    "imgs = [Image.open(p).convert(\"RGB\") for p in frame_paths]\n",
    "buffer = [np.array(im) for im in imgs]   # <-- ★ 여기! 리스트로 전달할 애"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "209de6db-f23b-4a28-852a-8d23cf85ab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip type: <class 'torch.Tensor'>\n",
      "clip shape: torch.Size([3, 8, 256, 256])\n",
      "normalized clip shape: torch.Size([3, 8, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# 3) processor로 clip 생성\n",
    "# ---------------------------------------\n",
    "inputs = processor(buffer)   # 보통 [clip_tensor] 형태\n",
    "\n",
    "if isinstance(inputs, list):\n",
    "    clip = inputs[0]\n",
    "else:\n",
    "    clip = inputs\n",
    "\n",
    "print(\"clip type:\", type(clip))\n",
    "print(\"clip shape:\", clip.shape)  # 예: (3, T, 256, 256) 또는 (T, 3, 256, 256)\n",
    "\n",
    "# clip을 (C, T, H, W)로 통일\n",
    "if clip.ndim == 4 and clip.shape[0] != 3:\n",
    "    # (T, C, H, W) → (C, T, H, W)\n",
    "    if clip.shape[1] == 3:\n",
    "        clip = clip.permute(1, 0, 2, 3)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected clip shape: {clip.shape}\")\n",
    "\n",
    "print(\"normalized clip shape:\", clip.shape)  # (3, T, H, W)\n",
    "\n",
    "C, T, H, W = clip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "481b193c-32f3-4b1f-9620-3ef615f47fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final W shape: torch.Size([7, 1408])\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# 4) 누적 world state w_t (t ≥ 2) 계산\n",
    "# ---------------------------------------\n",
    "# V-JEPA2 patch_embed3D의 temporal kernel size = 2 이므로\n",
    "# 최소 T=2 이상부터 입력 가능\n",
    "min_T = 2\n",
    "if T < min_T:\n",
    "    raise ValueError(f\"Need at least {min_T} frames, but got T={T}\")\n",
    "\n",
    "w_list = []\n",
    "\n",
    "for t in range(min_T, T + 1):\n",
    "    # 앞 t개 프레임 사용: (3, t, H, W)\n",
    "    clip_t = clip[:, :t, :, :]\n",
    "    video_t = clip_t.unsqueeze(0).to(device)  # (1, 3, t, H, W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_t = vjepa2_encoder(video_t)       # (B, N, D) or dict\n",
    "\n",
    "    # encoder output에서 토큰 텐서 선택\n",
    "    if isinstance(out_t, dict):\n",
    "        if \"x\" in out_t:\n",
    "            tokens = out_t[\"x\"]\n",
    "        else:\n",
    "            tokens = None\n",
    "            for k, v in out_t.items():\n",
    "                if torch.is_tensor(v):\n",
    "                    tokens = v\n",
    "                    # print(\"using key:\", k)\n",
    "                    break\n",
    "            if tokens is None:\n",
    "                raise RuntimeError(\"No tensor output found in encoder dict.\")\n",
    "    else:\n",
    "        tokens = out_t\n",
    "\n",
    "    # tokens: (1, N, D) → 평균해서 world state w_t (1, D)\n",
    "    w_t = tokens.mean(dim=1)\n",
    "    w_list.append(w_t)\n",
    "\n",
    "# (T - min_T + 1, D) 형태로 stack\n",
    "W = torch.cat(w_list, dim=0)  # shape: ((T-1), D)  ← 여기서 첫 행이 w_2에 해당\n",
    "print(\"Final W shape:\", W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d81cdbf2-b38f-45fd-86d4-f64e9b30c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vel_norm_per_step: tensor([ 0.0000, 10.9501,  0.0000,  9.8504,  0.0000,  9.5318], device='cuda:0')\n",
      "acc_norm_per_step: tensor([10.9501, 10.9501,  9.8504,  9.8504,  9.5318], device='cuda:0')\n",
      "vel_loss: 0.03643355518579483\n",
      "phys_loss: 0.07453503459692001\n"
     ]
    }
   ],
   "source": [
    "# W: shape (T-1, D)  # 여기서는 (7, 1408)\n",
    "# 인덱스 매핑: W[0] = w2, W[1] = w3, ..., W[6] = w8\n",
    "\n",
    "# 1) 1차 차분: world-state velocity-like 벡터\n",
    "vel = W[1:, :] - W[:-1, :]          # shape: (6, 1408)\n",
    "\n",
    "# 2) 2차 차분: world-state acceleration-like 벡터\n",
    "acc = vel[1:, :] - vel[:-1, :]      # shape: (5, 1408)\n",
    "\n",
    "# 3) 간단한 스칼라 지표들\n",
    "vel_norm_per_step = vel.norm(dim=1)     # (6,) – 각 step마다 state 변화량\n",
    "acc_norm_per_step = acc.norm(dim=1)     # (5,) – 각 step마다 가속도 변화량\n",
    "\n",
    "vel_loss  = (vel**2).mean()             # 전체 velocity 에너지\n",
    "phys_loss = (acc**2).mean()             # 전체 가속도 변화량 (부드러움/물리성)\n",
    "\n",
    "print(\"vel_norm_per_step:\", vel_norm_per_step)\n",
    "print(\"acc_norm_per_step:\", acc_norm_per_step)\n",
    "print(\"vel_loss:\", vel_loss.item())\n",
    "print(\"phys_loss:\", phys_loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
