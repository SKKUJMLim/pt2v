{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8dab41-4ce2-47f9-8a37-9627031ddb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ac6ddb-707f-49b0-a866-877c925bbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import sys, os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# (선택) decord로 비디오 읽기 – 안 쓰고 직접 frame 텐서를 만들고 싶으면 이 부분만 바꿔도 됨\n",
    "from decord import VideoReader, cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628c163d-e526-461a-9af8-e22e342fe24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JM\\anaconda3\\envs\\t2v\\lib\\site-packages\\accelerate\\utils\\torch_xla.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "C:\\Users\\JM\\PycharmProjects\\Text2Video-Zero-main\\annotator\\openpose\\body.py:5: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n",
      "C:\\Users\\JM\\PycharmProjects\\Text2Video-Zero-main\\annotator\\openpose\\hand.py:6: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n",
      "C:\\Users\\JM\\anaconda3\\envs\\t2v\\lib\\site-packages\\skimage\\util\\dtype.py:27: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0199d027-bc4a-4f69-964b-a1f83bab2800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\JM/.cache\\torch\\hub\\facebookresearch_vjepa2_main\n",
      "Using cache found in C:\\Users\\JM/.cache\\torch\\hub\\facebookresearch_vjepa2_main\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 1. device 설정 & 모델 / preprocessor 로드\n",
    "# -----------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# torch.hub에서 preprocessor / encoder 로드\n",
    "processor = torch.hub.load('facebookresearch/vjepa2', 'vjepa2_preprocessor')\n",
    "loaded  = torch.hub.load('facebookresearch/vjepa2', 'vjepa2_vit_giant')\n",
    "\n",
    "if isinstance(loaded, tuple):\n",
    "    vjepa2_encoder = loaded[0]    # encoder만 사용\n",
    "else:\n",
    "    vjepa2_encoder = loaded\n",
    "\n",
    "vjepa2_encoder = vjepa2_encoder.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9083ec69-9d29-4cd7-adb1-40ad671c979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: ['../frames\\\\_0.jpg', '../frames\\\\_1.jpg', '../frames\\\\_2.jpg', '../frames\\\\_3.jpg', '../frames\\\\_4.jpg', '../frames\\\\_5.jpg', '../frames\\\\_6.jpg', '../frames\\\\_7.jpg']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 2. frames 폴더에서 _0.jpg ~ _7.jpg 읽기\n",
    "# ---------------------------------------------------\n",
    "frames_dir = \"../frames\"\n",
    "\n",
    "# 파일 목록 정렬 (_0.jpg, _1.jpg, ... 순서 보장)\n",
    "frame_paths = glob.glob(os.path.join(frames_dir, \"*.jpg\"))\n",
    "\n",
    "def frame_key(path):\n",
    "    # 예: path = \"frames/_3.jpg\" -> stem = \"_3\" -> idx = 3\n",
    "    name = os.path.splitext(os.path.basename(path))[0]  # \"_3\"\n",
    "    idx = int(name.split(\"_\")[-1])\n",
    "    return idx\n",
    "\n",
    "frame_paths = sorted(frame_paths, key=frame_key)\n",
    "\n",
    "print(\"frames:\", frame_paths)\n",
    "\n",
    "# 각 프레임을 np.ndarray(H,W,3)로 읽어서 리스트로 만들기\n",
    "imgs = [Image.open(p).convert(\"RGB\") for p in frame_paths]\n",
    "buffer = [np.array(im) for im in imgs]   # <-- ★ 여기! 리스트로 전달할 애"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "209de6db-f23b-4a28-852a-8d23cf85ab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip type: <class 'torch.Tensor'>\n",
      "clip shape: torch.Size([3, 8, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JM\\anaconda3\\envs\\t2v\\lib\\contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats type: <class 'torch.Tensor'>\n",
      "feats shape: torch.Size([1, 1024, 1408])\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 2) processor + encoder\n",
    "# ---------------------------------------------------\n",
    "# processor는 \"프레임 리스트\"를 기대함\n",
    "inputs = processor(buffer)   # 여기서 VideoTransform.__call__이 돌아감\n",
    "\n",
    "# 보통 [clip_tensor] 형태로 나옴\n",
    "if isinstance(inputs, list):\n",
    "    clip = inputs[0]\n",
    "else:\n",
    "    clip = inputs\n",
    "\n",
    "print(\"clip type:\", type(clip))\n",
    "if torch.is_tensor(clip):\n",
    "    print(\"clip shape:\", clip.shape)  # 기대: (T, 3, H, W) 또는 (3, H, W, T 등)\n",
    "else:\n",
    "    raise TypeError(f\"Unexpected clip type from processor: {type(clip)}\")\n",
    "\n",
    "# 만약 shape가 (T, H, W, 3)이면, 아래처럼 바꿀 수도 있음:\n",
    "if clip.ndim == 4 and clip.shape[-1] == 3:\n",
    "    # (T, H, W, 3) -> (T, 3, H, W)\n",
    "    clip = clip.permute(0, 3, 1, 2)\n",
    "\n",
    "# 이제 encoder에 넣을 입력 텐서\n",
    "video_tensor = clip.unsqueeze(0).to(device)   # torch.Size([1, 3, 8, 256, 256])\n",
    "\n",
    "with torch.no_grad():\n",
    "    feats = vjepa2_encoder(video_tensor)\n",
    "\n",
    "print(\"feats type:\", type(feats))\n",
    "if torch.is_tensor(feats):\n",
    "    print(\"feats shape:\", feats.shape)\n",
    "else:\n",
    "    for k, v in feats.items():\n",
    "        if torch.is_tensor(v):\n",
    "            print(\"feat:\", k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b193c-32f3-4b1f-9620-3ef615f47fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
